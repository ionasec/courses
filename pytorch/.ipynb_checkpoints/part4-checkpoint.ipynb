{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c800ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e15447b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287175b62fd8424e85045a903d954043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4653bfcca64d7197a5e3aade240b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d2c96bdeb64f4f9a0a211a529a267a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b1f6db97a14059af013787d591366e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST(\"\",train=True, download=True, transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3047d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.MNIST(\"\",train=False, download=True, transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c1c4c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e3e5eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d4b873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77d9547f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax (x, dim=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "net = Net()\n",
    "print(net)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fdef164",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(1,28*28)\n",
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fe75bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3955, -2.2846, -2.2082, -2.3329, -2.4814, -2.2066, -2.2597, -2.3405,\n",
       "         -2.3302, -2.2209]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56cd016c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0071, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0040, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2180, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range (EPOCHS):\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "526fbe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.975\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "pass = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        pass +=1\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,28*28))\n",
    "        for idx, i in enumerate (output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total +=1\n",
    "            \n",
    "print(\"Accuracy\", round(correct / total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7431d9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe920009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b9ed63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[0].view(-1,784))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1aa2de04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0994796d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: \n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360a95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dac3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p36",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
